{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor  \n",
    "from sklearn import cross_validation, metrics   \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.pipeline import Pipeline\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"energydata_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "df['weekday'] = df['date'].dt.strftime('%A')\n",
    "\n",
    "df['Month'] = df['date'].dt.strftime('%m').astype('int64')\n",
    "\n",
    "df['Week_no'] = df['date'].dt.strftime('%W').astype('int64')\n",
    "\n",
    "df['Hour_of_the_day'] = df['date'].dt.strftime('%H').astype('int64')\n",
    "\n",
    "df['NSM'] = df['date'].dt.strftime('%H:%M:%S')\n",
    "df['NSM'] = df['NSM'].str.split(':').apply(lambda x: int(x[0]) * 3600 + int(x[1]) *60 + int(x[2]))\n",
    "\n",
    "df['WeekStatus'] = (df['date'].dt.strftime('%w').astype(int) < 5).astype('int64')\n",
    "\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "W_Status = pd.get_dummies(df.WeekStatus,prefix='W_Status').astype('int64')\n",
    "Day_W = pd.get_dummies(df.weekday, prefix = 'Dy_w').astype('int64')\n",
    "\n",
    "df = pd.concat([df,W_Status,Day_W],axis=1)\n",
    "\n",
    "featureColumns = ['Appliances','NSM','lights','T1','RH_1','T2','RH_2','T3','RH_3','T4','RH_4','T5','RH_5','T6','RH_6',\n",
    "                  'T7','RH_7','T8','RH_8','T9','RH_9','T_out','RH_out','Visibility','Windspeed','Tdewpoint',\n",
    "                  'Press_mm_hg','W_Status_1','W_Status_0',\n",
    "                  'Dy_w_Monday','Dy_w_Tuesday','Dy_w_Wednesday','Dy_w_Thursday',\n",
    "                  'Dy_w_Friday','Dy_w_Saturday','Dy_w_Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression completed\n",
      "RandomForest completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network completed\n",
      "Gradient Boosting completed\n",
      "Best Model is  RandomForest\n",
      "Error Metrics are:\n",
      "                       Model   mae_test  mae_train  mape_test  mape_train  \\\n",
      "0                 Regression  52.954546  53.124709  63.023106   61.001825   \n",
      "0               RandomForest  29.873619  11.614168  29.666864   11.366604   \n",
      "0             Nueral Network  53.071808  53.525017  62.485122   60.763316   \n",
      "0  GradientBoostingRegressor  42.737999  38.760498  47.594908   42.556737   \n",
      "\n",
      "    r2_test  r2_train   rms_test  rms_train  \n",
      "0  0.163900  0.176196  91.135629  93.898834  \n",
      "0  0.593532  0.941868  63.543667  24.943305  \n",
      "0  0.136455  0.138665  92.619293  96.013924  \n",
      "0  0.370016  0.534229  79.108608  70.604824  \n"
     ]
    }
   ],
   "source": [
    "df = df[featureColumns]\n",
    "\n",
    "X = df.drop(['Appliances'],axis=1)\n",
    "y = df['Appliances']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "\n",
    "error_metric = pd.DataFrame({'r2_train': [],\n",
    "                            'r2_test': [],\n",
    "                             'rms_train':[], \n",
    "                            'rms_test': [],\n",
    "                            'mae_train': [],\n",
    "                            'mae_test':[],\n",
    "                            'mape_train':[],\n",
    "                            'mape_test':[]})\n",
    "    \n",
    "rmse_dict = {}    \n",
    "        \n",
    "def calc_error_metric(modelname, model, X_train_scale, y_train, X_test_scale, y_test):\n",
    "    global error_metric\n",
    "    y_train_predicted = model.predict(X_train)\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "        \n",
    "    #MAE, RMS, MAPE, R2\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_train_predicted)\n",
    "    r2_test = r2_score(y_test, y_test_predicted)\n",
    "    \n",
    "    rms_train = sqrt(mean_squared_error(y_train, y_train_predicted))\n",
    "    rms_test = sqrt(mean_squared_error(y_test, y_test_predicted))\n",
    "        \n",
    "    mae_train = mean_absolute_error(y_train, y_train_predicted)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_predicted)\n",
    "        \n",
    "    mape_train = np.mean(np.abs((y_train - y_train_predicted) / y_train)) * 100\n",
    "    mape_test = np.mean(np.abs((y_test - y_test_predicted) / y_test)) * 100\n",
    "        \n",
    "    rmse_dict[modelname] = rms_test\n",
    "        \n",
    "    df_local = pd.DataFrame({'Model':[modelname],\n",
    "                            'r2_train': [r2_train],\n",
    "                            'r2_test': [r2_test],\n",
    "                            'rms_train':[rms_train], \n",
    "                            'rms_test': [rms_test],\n",
    "                            'mae_train': [mae_train],\n",
    "                            'mae_test': [mae_test],\n",
    "                            'mape_train':[mape_train],\n",
    "                            'mape_test':[mape_test]})\n",
    "        \n",
    "    error_metric = pd.concat([error_metric, df_local])\n",
    "    return error_metric\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', LinearRegression(normalize=True))])\n",
    "grid_params_lr =[{}]\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr, param_grid=grid_params_lr, cv=10) \n",
    "gs_lr.fit(X_train, y_train)\n",
    "calc_error_metric('Regression', gs_lr, X_train, y_train, X_test, y_test)\n",
    "print('Regression completed')\n",
    "\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),('rf', RandomForestRegressor(n_estimators=115,max_features=6,random_state=42))])\n",
    "grid_params_rf = [{}]\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf, param_grid=grid_params_rf, cv=10)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "calc_error_metric('RandomForest', gs_rf, X_train, y_train, X_test, y_test)\n",
    "print('RandomForest completed')\n",
    "\n",
    "pipe_nn = Pipeline([('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "                    ('neural network', MLPRegressor(activation = 'logistic',learning_rate='adaptive',alpha=0.5))])\n",
    "grid_params_nn = [{}]\n",
    "gs_nn = GridSearchCV(estimator=pipe_nn, param_grid=grid_params_nn, cv=10)\n",
    "gs_nn.fit(X_train, y_train)\n",
    "calc_error_metric('Nueral Network', gs_nn, X_train, y_train, X_test, y_test)\n",
    "print('Neural Network completed')\n",
    "\n",
    "pipe_gbm = Pipeline([('scl', StandardScaler()),('gbm', GradientBoostingRegressor(n_estimators=300,learning_rate= 0.1,max_features=1.0,random_state=42))])\n",
    "grid_params_gbm =[{}]\n",
    "gs_gbm = GridSearchCV(estimator=pipe_gbm, param_grid=grid_params_gbm, cv=10)\n",
    "gs_gbm.fit(X_train, y_train)\n",
    "calc_error_metric('GradientBoostingRegressor', gs_gbm, X_train, y_train, X_test, y_test)\n",
    "print('Gradient Boosting completed')\n",
    "\n",
    "#### Calculate best model\n",
    "best_model =  min(rmse_dict.items(),key=operator.itemgetter(1))[0]\n",
    "print('Best Model is ', best_model)\n",
    "\n",
    "print('Error Metrics are:')\n",
    "print(error_metric)\n",
    "\n",
    "#### Write the error\n",
    "error_metric.to_csv('Error_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
