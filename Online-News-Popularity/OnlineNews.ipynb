{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable for storing models\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read json file\n",
    "def to_read_json(filename,title):\n",
    "    data = pd.read_json(filename,orient='columns')\n",
    "    data_format = pd.read_json(([title]).to_json(),orient='index')\n",
    "    return data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read csv file\n",
    "def to_read_csv(csvfile):\n",
    "    df = pd.read_csv(csvfile,index_col=None,header=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make directory\n",
    "def make_directory():\n",
    "    try:\n",
    "        if not os.path.exists('ADS_Assignment3'):\n",
    "            os.makedirs('ADS_Assignment3', mode=0o777)\n",
    "        else:\n",
    "            shutil.rmtree(os.path.join(os.path.dirname(__file__),'ADS_Assignment3'),ignore_errors=False)\n",
    "            os.makedirs('ADS_Assignment3', mode=0o777)\n",
    "    except Exception as e:\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_standardization\n",
    "from sklearn import preprocessing\n",
    "def data_standardization(X):\n",
    "    standardized_X = pd.DataFrame(preprocessing.scale(X),index =X.index,columns = X.columns)\n",
    "    return standardized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def minmaxscaling(X):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_minmax=pd.DataFrame(min_max.fit_transform(X),index =X.index,columns = X.columns)\n",
    "    return X_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "def train_test_split_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_precision(name,label, prediction):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    # test\n",
    "    for i in range(0, len(label)):\n",
    "        if prediction[i] == 1:\n",
    "            if prediction[i] == label[i]:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "        else:\n",
    "            if prediction[i] == label[i]:\n",
    "                true_negatives += 1\n",
    "            else:\n",
    "                false_negatives += 1\n",
    "                \n",
    "    print('TruePositive_test ',true_positives)\n",
    "    print('TrueNegative_test ',true_negatives)\n",
    "    print('FlasePositive_test ',false_positives)\n",
    "    print('FalseNegative_test ',false_negatives)  \n",
    "    # a ratio of correctly predicted observation to the total observations\n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "\n",
    "    # precision is \"how useful the search results are\"\n",
    "    try :\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        \n",
    "    # recall is \"how complete the results are\"\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    #f1_score\n",
    "    f1_score = 2 / ((1 / precision) + (1 / recall))\n",
    "    #specificity\n",
    "    specificity = true_negatives/((true_negatives + false_positives))\n",
    "    \n",
    "    df_local = pd.DataFrame({'Model':[name],'Precision': [precision],\n",
    "                             'Recall': [recall],'F1_score':[f1_score],\n",
    "                             'Accuracy': [accuracy],'Specificity': [specificity]})\n",
    "    error_metric = pd.concat([df_local])\n",
    " \n",
    "    return error_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_precision(name,label, prediction):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    # test\n",
    "    for i in range(0, len(label)):\n",
    "        if prediction[i] == 1:\n",
    "            if prediction[i] == label[i]:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "        else:\n",
    "            if prediction[i] == label[i]:\n",
    "                true_negatives += 1\n",
    "            else:\n",
    "                false_negatives += 1\n",
    "                \n",
    "    print('TruePositive_test ',true_positives)\n",
    "    print('TrueNegative_test ',true_negatives)\n",
    "    print('FlasePositive_test ',false_positives)\n",
    "    print('FalseNegative_test ',false_negatives)  \n",
    "    # a ratio of correctly predicted observation to the total observations\n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "\n",
    "    # precision is \"how useful the search results are\"\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    # recall is \"how complete the results are\"\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    #f1_score\n",
    "    f1_score = 2 / ((1 / precision) + (1 / recall))\n",
    "    #specificity\n",
    "    specificity = true_negatives/((true_negatives + false_positives))\n",
    "    \n",
    "    df_local = pd.DataFrame({'Model':[name],'Precision': [precision],\n",
    "                             'Recall': [recall],'F1_score':[f1_score],\n",
    "                             'Accuracy': [accuracy],'Specificity': [specificity]})\n",
    "    error_metric = pd.concat([df_local])\n",
    " \n",
    "    return error_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def logistic_regression_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    lr = LogisticRegression()\n",
    "    scores = cross_val_score(lr,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2 \n",
    "    lr.fit(X_train,y_train)\n",
    "    models.append(lr)\n",
    "    log = calculate_recall_precision('LogisticRegression',y_test,lr.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    log['Accuract with cv'] = scores1\n",
    "    log['Deviation(+/-)'] = deviation\n",
    "    log['time'] = t\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def naive_bayers_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    nb = GaussianNB()\n",
    "    scores = cross_val_score(nb,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    nb.fit(X_train,y_train)\n",
    "    models.append(nb)\n",
    "    naive = calculate_recall_precision('NaiveBayers',y_test,nb.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    naive['Accuract with cv'] = scores1\n",
    "    naive['Deviation(+/-)'] = deviation\n",
    "    naive['time'] = t\n",
    "    return naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "def support_vector_machine_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    svm = SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
    "    scores = cross_val_score(svm,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    svm.fit(X_train,y_train)\n",
    "    models.append(svm)\n",
    "    svmachine =calculate_recall_precision('SupportVectorMachine',y_test,svm.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    svmachine['Accuract with cv'] = scores1\n",
    "    svmachine['Deviation(+/-)'] = deviation\n",
    "    svmachine['time'] = t\n",
    "    return svmachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DecisionTreeClassifier_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    dtree = DecisionTreeClassifier(max_depth=10,random_state=101,max_features= None, min_samples_leaf = 15)\n",
    "    scores = cross_val_score(dtree,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    dtree.fit(X_train,y_train)\n",
    "    models.append(dtree)\n",
    "    decision = calculate_recall_precision('DecisionTree',y_test,dtree.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    decision['Accuract with cv'] = scores1\n",
    "    decision['Deviation(+/-)'] = deviation\n",
    "    decision['time'] = t\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def AdaBoostClassifier_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    clf = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "    scores = cross_val_score(clf,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    clf.fit(X_train,y_train)\n",
    "    models.append(clf)\n",
    "    ada = calculate_recall_precision('AdaptiveBoosting',y_test,clf.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    ada['Accuract with cv'] = scores1\n",
    "    ada['Deviation(+/-)'] = deviation\n",
    "    ada['time'] = t\n",
    "    return ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClasssifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForestClassifier_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    rfm = RandomForestClassifier(n_estimators= 70,n_jobs=-1,random_state = 101,max_features = None, min_samples_leaf = 30)\n",
    "    scores = cross_val_score(rfm,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    rfm.fit(X_train,y_train)\n",
    "    models.append(rfm)\n",
    "    random = calculate_recall_precision('RandomForest',y_test,rfm.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    random['Accuract with cv'] = scores1\n",
    "    random['Deviation(+/-)'] = deviation\n",
    "    random['time'] = t    \n",
    "    return random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest-NeighborClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def knn_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    knn = KNeighborsClassifier(n_neighbors=15)\n",
    "    scores = cross_val_score(knn,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    knn.fit(X_train,y_train)\n",
    "    models.append(knn)\n",
    "    nearest = calculate_recall_precision('K-NearestNeighbours',y_test,knn.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    nearest['Accuract with cv'] = scores1\n",
    "    nearest['Deviation(+/-)'] = deviation\n",
    "    nearest['time'] = t \n",
    "    return nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNetwork\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def NeuralNetworkClassifier_model(X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split_model(X,y)\n",
    "    t1=time()\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "    scores = cross_val_score(mlp,X,y, cv=20)\n",
    "    scores1 = scores.mean()\n",
    "    deviation = scores.std() * 2\n",
    "    mlp.fit(X_train,y_train)\n",
    "    models.append(mlp)\n",
    "    neural = calculate_recall_precision('NeuralNetwork',y_test,mlp.predict(X_test))\n",
    "    t2=time()\n",
    "    t = t2-t1\n",
    "    neural['Accuract with cv'] = scores1\n",
    "    neural['Deviation(+/-)'] = deviation\n",
    "    neural['time'] = t \n",
    "    return neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_classification_model(X,y):\n",
    "    # added\n",
    "    #accuracy_score(y_test,y_predict)\n",
    "    names = [\"LogisticRegression\",\"NaiveBayers\",\"SupportVectorMachine\",\"DecisionTree\",\"ADABoostClassifier\",\"RandomForest\",\"knn\",\"NeuralNetwork\"]\n",
    "    logistic = logistic_regression_model(X,y)\n",
    "    print('logistic done')\n",
    "    naive = naive_bayers_model(X,y)\n",
    "    print('naive bayers done')\n",
    "    svm = support_vector_machine_model(X,y)\n",
    "    print('svm done')\n",
    "    decision = DecisionTreeClassifier_model(X,y)\n",
    "    print('decision tree done')\n",
    "    ada = AdaBoostClassifier_model(X,y)\n",
    "    print('ada done')\n",
    "    randomforest = RandomForestClassifier_model(X,y)\n",
    "    print('random done')\n",
    "    knn = knn_model(X,y)\n",
    "    print('knn done')\n",
    "    nn = NeuralNetworkClassifier_model(X,y)\n",
    "    \n",
    "    all_cl = pd.concat([logistic,naive,svm,decision,ada,randomforest,knn,nn])\n",
    "    print('nn done')\n",
    "    return all_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"OnlineNewsPopularity.csv\"\n",
    "df = to_read_csv(file)\n",
    "#df.set_index('url', inplace=True)\n",
    "df = df.drop(['url'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaling\n",
    "df_minmax = minmaxscaling(df_copy.drop([' shares'],axis=1))\n",
    "# Standardization\n",
    "df_std = data_standardization(df_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 60)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std[' shares'] = df_copy[' shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.695210</td>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.038658</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>-0.708369</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>-0.969886</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>-0.975432</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>0.138920</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.618794</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>1.102174</td>\n",
       "      <td>1.367424</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.712192</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-1.621797</td>\n",
       "      <td>-0.957871</td>\n",
       "      <td>-0.270867</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.032933</td>\n",
       "      <td>-0.012619</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>-0.166229</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>-0.862584</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>-0.620377</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>1.115439</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.045420</td>\n",
       "      <td>0.716237</td>\n",
       "      <td>4.074185</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.307944</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.531059</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.374685</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>-0.783956</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>0.505184</td>\n",
       "      <td>0.420082</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>1.111832</td>\n",
       "      <td>0.538188</td>\n",
       "      <td>-1.054014</td>\n",
       "      <td>0.257288</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>0.877699</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.042680</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>4.333583</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.274380</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.939257</td>\n",
       "      <td>-0.032563</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.035858</td>\n",
       "      <td>0.804484</td>\n",
       "      <td>4.333583</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.131114</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>1.614540</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>1.519883</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-0.954178</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>-0.783956</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>4.270611</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>1.053240</td>\n",
       "      <td>1.367424</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.485294</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.175632</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.669738</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>0.167775</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>1.489032</td>\n",
       "      <td>-0.016521</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-1.217781</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.763136</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>-0.342723</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.466113</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>-0.023299</td>\n",
       "      <td>0.420082</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.578463</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.627991</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.776941</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.466113</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>-0.398457</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.555113</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>4.807953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905214</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-0.613547</td>\n",
       "      <td>-0.613383</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>-0.610303</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.013701</td>\n",
       "      <td>0.716237</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>0.536248</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>0.946052</td>\n",
       "      <td>1.152119</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>1.442271</td>\n",
       "      <td>1.802901</td>\n",
       "      <td>-0.486485</td>\n",
       "      <td>1.740837</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.287592</td>\n",
       "      <td>-0.025187</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>-0.077983</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637259</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>0.308276</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>1.442271</td>\n",
       "      <td>-1.210884</td>\n",
       "      <td>-0.486485</td>\n",
       "      <td>0.415112</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>1.213083</td>\n",
       "      <td>-0.010174</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>1.333964</td>\n",
       "      <td>3.814788</td>\n",
       "      <td>0.897288</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-1.111087</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.876852</td>\n",
       "      <td>-0.645799</td>\n",
       "      <td>-1.457590</td>\n",
       "      <td>-0.247750</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>-0.317373</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.035682</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>1.109058</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-0.941442</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>1.053240</td>\n",
       "      <td>1.367424</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>1.772711</td>\n",
       "      <td>-2.959956</td>\n",
       "      <td>0.081044</td>\n",
       "      <td>2.466829</td>\n",
       "      <td>5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>1.402002</td>\n",
       "      <td>-0.039094</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.042945</td>\n",
       "      <td>1.157470</td>\n",
       "      <td>5.371171</td>\n",
       "      <td>4.507687</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.256321</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>17100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>1.489032</td>\n",
       "      <td>-0.044758</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.050781</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>4.074185</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.414773</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.330109</td>\n",
       "      <td>-0.010782</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.011999</td>\n",
       "      <td>-0.166229</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637259</td>\n",
       "      <td>-1.641469</td>\n",
       "      <td>1.183730</td>\n",
       "      <td>1.223887</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>1.289500</td>\n",
       "      <td>-0.034343</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.035641</td>\n",
       "      <td>0.804484</td>\n",
       "      <td>4.333583</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.229095</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-0.894743</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>-0.872203</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>0.517040</td>\n",
       "      <td>1.237817</td>\n",
       "      <td>-1.545872</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>-0.642143</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-1.305153</td>\n",
       "      <td>-1.542053</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>1.288066</td>\n",
       "      <td>-1.775969</td>\n",
       "      <td>-0.751332</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>-0.595444</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>-0.519216</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>2.167238</td>\n",
       "      <td>-1.641469</td>\n",
       "      <td>1.118485</td>\n",
       "      <td>1.109058</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>1.904887</td>\n",
       "      <td>1.237817</td>\n",
       "      <td>0.308055</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>-0.457470</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>-0.519216</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-0.034173</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>1.440210</td>\n",
       "      <td>-0.046231</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.055335</td>\n",
       "      <td>0.980977</td>\n",
       "      <td>4.852377</td>\n",
       "      <td>2.822834</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637259</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.448095</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>1.614540</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>1.519883</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.644266</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>-0.872203</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>0.642198</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>0.374623</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.014376</td>\n",
       "      <td>0.627991</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.357296</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>1.614540</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>1.519883</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39614</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>0.758828</td>\n",
       "      <td>-0.021603</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.025225</td>\n",
       "      <td>1.422210</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.306179</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>0.264865</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39615</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>1.980408</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>0.531059</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39616</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>2.176551</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>0.531059</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39617</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>0.943502</td>\n",
       "      <td>-0.025291</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.021652</td>\n",
       "      <td>2.569417</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637259</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.531059</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39618</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>0.275004</td>\n",
       "      <td>1.480214</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>0.694394</td>\n",
       "      <td>0.936814</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.485294</td>\n",
       "      <td>-0.739980</td>\n",
       "      <td>0.175632</td>\n",
       "      <td>-0.137273</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>-0.251569</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>-0.783956</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>-0.093204</td>\n",
       "      <td>-0.613383</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39620</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>-0.283410</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>-2.078510</td>\n",
       "      <td>-0.785627</td>\n",
       "      <td>-2.018414</td>\n",
       "      <td>1.133861</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>-1.016179</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39621</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.166662</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.539744</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>-0.179887</td>\n",
       "      <td>-0.613383</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>24300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39622</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>1.221574</td>\n",
       "      <td>-0.030902</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.016515</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>0.175208</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-0.023299</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.358796</td>\n",
       "      <td>-0.751332</td>\n",
       "      <td>0.046856</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39623</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>-0.234588</td>\n",
       "      <td>-0.005341</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>-0.430969</td>\n",
       "      <td>0.702022</td>\n",
       "      <td>-0.306179</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>0.033790</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>1.750682</td>\n",
       "      <td>-1.775969</td>\n",
       "      <td>0.043208</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39624</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.249447</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.009415</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>-0.185832</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998697</td>\n",
       "      <td>-0.027151</td>\n",
       "      <td>0.623823</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>0.865038</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39625</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>-0.684597</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>-0.342723</td>\n",
       "      <td>0.961420</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>1.472671</td>\n",
       "      <td>1.551971</td>\n",
       "      <td>0.378222</td>\n",
       "      <td>1.596477</td>\n",
       "      <td>1.237817</td>\n",
       "      <td>-0.221638</td>\n",
       "      <td>1.077975</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39626</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.890128</td>\n",
       "      <td>1.223887</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39627</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>0.695148</td>\n",
       "      <td>-0.019176</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.186757</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.632520</td>\n",
       "      <td>-0.512635</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>0.909563</td>\n",
       "      <td>-0.765666</td>\n",
       "      <td>-1.401410</td>\n",
       "      <td>-0.107143</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39628</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.703516</td>\n",
       "      <td>0.168722</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.021630</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>-2.339489</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39629</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>-0.716437</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>0.182610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.466113</td>\n",
       "      <td>0.376429</td>\n",
       "      <td>-0.838859</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>-2.152692</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>1.519883</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39630</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.117840</td>\n",
       "      <td>-0.026713</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.024354</td>\n",
       "      <td>-0.783956</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.306179</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461978</td>\n",
       "      <td>0.578218</td>\n",
       "      <td>0.740997</td>\n",
       "      <td>0.649740</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.601152</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>-1.690334</td>\n",
       "      <td>0.053551</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39631</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>0.423444</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.376429</td>\n",
       "      <td>-0.904104</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39632</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>2.176551</td>\n",
       "      <td>0.071079</td>\n",
       "      <td>-0.011917</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.008357</td>\n",
       "      <td>0.363251</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.185832</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>1.131534</td>\n",
       "      <td>1.367424</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>1.614540</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>1.519883</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39633</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>0.143250</td>\n",
       "      <td>-0.020503</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.022724</td>\n",
       "      <td>-0.077983</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637259</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>0.612343</td>\n",
       "      <td>0.764570</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39634</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.627285</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>2.517803</td>\n",
       "      <td>0.536248</td>\n",
       "      <td>0.182610</td>\n",
       "      <td>...</td>\n",
       "      <td>2.167238</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-2.339489</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39635</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>-0.145435</td>\n",
       "      <td>-0.009707</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.014498</td>\n",
       "      <td>0.627991</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.306179</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.281177</td>\n",
       "      <td>0.420082</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.562396</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.308055</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>4.165737</td>\n",
       "      <td>-0.056619</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.068688</td>\n",
       "      <td>1.069224</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>0.656594</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.218538</td>\n",
       "      <td>-0.268895</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39637</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>2.297775</td>\n",
       "      <td>-0.034796</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.025448</td>\n",
       "      <td>0.363251</td>\n",
       "      <td>2.258405</td>\n",
       "      <td>0.175208</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>-1.331073</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>1.545075</td>\n",
       "      <td>-2.529415</td>\n",
       "      <td>-0.309921</td>\n",
       "      <td>1.961791</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39638</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-0.686720</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.041835</td>\n",
       "      <td>-0.519216</td>\n",
       "      <td>-0.076169</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666435</td>\n",
       "      <td>0.174639</td>\n",
       "      <td>0.074568</td>\n",
       "      <td>0.936814</td>\n",
       "      <td>-1.494150</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>-0.425630</td>\n",
       "      <td>-0.005443</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>-0.166229</td>\n",
       "      <td>0.961420</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.027151</td>\n",
       "      <td>-0.003726</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>-0.183490</td>\n",
       "      <td>-0.562396</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.308055</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.463838</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>-0.166229</td>\n",
       "      <td>0.961420</td>\n",
       "      <td>-0.185832</td>\n",
       "      <td>11.380809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-0.228941</td>\n",
       "      <td>0.379044</td>\n",
       "      <td>0.420082</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>3.498156</td>\n",
       "      <td>-0.751332</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.221852</td>\n",
       "      <td>-0.009050</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.013798</td>\n",
       "      <td>1.157470</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>0.897288</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573773</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>-0.758786</td>\n",
       "      <td>-0.957871</td>\n",
       "      <td>-0.620377</td>\n",
       "      <td>0.531059</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>-2.080761</td>\n",
       "      <td>0.287592</td>\n",
       "      <td>-0.002477</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>-0.077983</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461978</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>0.424968</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>0.996104</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>-0.188622</td>\n",
       "      <td>-0.826817</td>\n",
       "      <td>0.043677</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.048082</td>\n",
       "      <td>-0.872203</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>0.182610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>0.466037</td>\n",
       "      <td>1.109058</td>\n",
       "      <td>-0.969886</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.672732</td>\n",
       "      <td>-0.927896</td>\n",
       "      <td>0.415112</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0        1.757880         0.757447          -0.695210          0.032772   \n",
       "1        1.757880        -0.661657          -0.618794          0.016056   \n",
       "2        1.757880        -0.661657          -0.712192          0.007645   \n",
       "3        1.757880        -0.661657          -0.032933         -0.012619   \n",
       "4        1.757880         1.230482           1.115439         -0.037655   \n",
       "5        1.757880        -0.188622          -0.374685          0.003316   \n",
       "6        1.757880        -1.134691           0.877699         -0.036940   \n",
       "7        1.757880         0.757447           0.939257         -0.032563   \n",
       "8        1.757880         0.284413          -0.954178          0.034621   \n",
       "9        1.757880        -0.188622          -0.669738          0.025037   \n",
       "10       1.757880        -0.661657           1.489032         -0.016521   \n",
       "11       1.757880        -0.188622          -0.763136          0.033644   \n",
       "12       1.757880        -0.661657          -0.578463          0.017321   \n",
       "13       1.757880        -0.661657          -0.555113          0.055663   \n",
       "14       1.757880        -1.134691          -0.610303          0.004129   \n",
       "15       1.757880         0.757447           0.287592         -0.025187   \n",
       "16       1.757880        -1.134691           1.213083         -0.010174   \n",
       "17       1.757880        -1.134691          -0.317373          0.021718   \n",
       "18       1.757880         0.284413          -0.941442          0.040079   \n",
       "19       1.757880        -1.134691           1.402002         -0.039094   \n",
       "20       1.757880         1.230482           1.489032         -0.044758   \n",
       "21       1.757880        -0.661657          -0.330109         -0.010782   \n",
       "22       1.757880         0.284413           1.289500         -0.034343   \n",
       "23       1.757880         0.284413          -0.894743          0.035954   \n",
       "24       1.757880         1.230482          -0.642143          0.003347   \n",
       "25       1.757880        -1.134691          -0.595444          0.006921   \n",
       "26       1.757880        -1.134691          -0.457470          0.004112   \n",
       "27       1.757880         0.757447           1.440210         -0.046231   \n",
       "28       1.757880        -0.188622          -0.644266          0.020175   \n",
       "29       1.757880         0.284413           0.374623         -0.016270   \n",
       "...           ...              ...                ...               ...   \n",
       "39614   -1.613414        -0.661657           0.758828         -0.021603   \n",
       "39615   -1.613414         0.284413          -1.160078         -0.155714   \n",
       "39616   -1.613414         2.176551          -1.160078         -0.155714   \n",
       "39617   -1.613414         0.284413           0.943502         -0.025291   \n",
       "39618   -1.613414         1.703516          -0.124208         -0.008738   \n",
       "39619   -1.613414         1.703516          -0.251569         -0.010037   \n",
       "39620   -1.613414         1.230482          -0.283410          0.002403   \n",
       "39621   -1.613414        -0.661657          -0.166662          0.009818   \n",
       "39622   -1.613414         0.284413           1.221574         -0.030902   \n",
       "39623   -1.613414         1.703516          -0.234588         -0.005341   \n",
       "39624   -1.613414         0.757447          -0.249447         -0.009456   \n",
       "39625   -1.613414         1.230482          -0.684597          0.006226   \n",
       "39626   -1.613414         0.757447          -0.631530          0.005400   \n",
       "39627   -1.613414         1.703516           0.695148         -0.019176   \n",
       "39628   -1.613414         1.703516           0.168722          0.001218   \n",
       "39629   -1.613414         1.230482          -0.716437          0.030860   \n",
       "39630   -1.613414         0.757447          -0.117840         -0.026713   \n",
       "39631   -1.613414         1.230482           0.423444         -0.023549   \n",
       "39632   -1.613414         2.176551           0.071079         -0.011917   \n",
       "39633   -1.613414        -0.661657           0.143250         -0.020503   \n",
       "39634   -1.613414        -0.661657          -0.627285          0.033644   \n",
       "39635   -1.613414         1.230482          -0.145435         -0.009707   \n",
       "39636   -1.618083        -1.134691           4.165737         -0.056619   \n",
       "39637   -1.618083         1.230482           2.297775         -0.034796   \n",
       "39638   -1.618083         0.284413          -0.686720          0.029806   \n",
       "39639   -1.618083         0.284413          -0.425630         -0.005443   \n",
       "39640   -1.618083         0.757447          -0.463838          0.042060   \n",
       "39641   -1.618083        -0.188622          -0.221852         -0.009050   \n",
       "39642   -1.618083        -2.080761           0.287592         -0.002477   \n",
       "39643   -1.618083        -0.188622          -0.826817          0.043677   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "0               0.000675                   0.038658   -0.607463   \n",
       "1               0.000675                   0.031479   -0.695709   \n",
       "2               0.000675                  -0.007752   -0.695709   \n",
       "3               0.000675                  -0.007211   -0.166229   \n",
       "4               0.000675                  -0.045420    0.716237   \n",
       "5               0.000675                   0.002764   -0.783956   \n",
       "6               0.000675                  -0.042680    0.892731   \n",
       "7               0.000675                  -0.035858    0.804484   \n",
       "8               0.000675                   0.045197   -0.783956   \n",
       "9               0.000675                   0.033058   -0.607463   \n",
       "10              0.000675                   0.013006    0.010264   \n",
       "11              0.000675                   0.033946   -0.342723   \n",
       "12              0.000675                   0.005644    0.627991   \n",
       "13              0.000675                   0.046666   -0.607463   \n",
       "14              0.000675                  -0.013701    0.716237   \n",
       "15              0.000675                  -0.016606   -0.077983   \n",
       "16              0.000675                   0.006308    1.333964   \n",
       "17              0.000675                   0.035682    0.010264   \n",
       "18              0.000675                   0.035922   -0.695709   \n",
       "19              0.000675                  -0.042945    1.157470   \n",
       "20              0.000675                  -0.050781    0.892731   \n",
       "21              0.000675                  -0.011999   -0.166229   \n",
       "22              0.000675                  -0.035641    0.804484   \n",
       "23              0.000675                   0.033170   -0.872203   \n",
       "24              0.000675                  -0.002727   -0.695709   \n",
       "25              0.000675                   0.009775   -0.519216   \n",
       "26              0.000675                   0.010817   -0.519216   \n",
       "27              0.000675                  -0.055335    0.980977   \n",
       "28              0.000675                   0.041428   -0.872203   \n",
       "29              0.000675                  -0.014376    0.627991   \n",
       "...                  ...                        ...         ...   \n",
       "39614           0.000675                  -0.025225    1.422210   \n",
       "39615          -0.190487                  -0.211094   -0.960449   \n",
       "39616          -0.190487                  -0.211094   -0.960449   \n",
       "39617           0.000675                  -0.021652    2.569417   \n",
       "39618           0.000675                  -0.001738    0.275004   \n",
       "39619           0.000675                   0.002931   -0.783956   \n",
       "39620           0.000675                   0.001145    0.010264   \n",
       "39621           0.000675                   0.000656    0.539744   \n",
       "39622           0.000675                  -0.016515   -0.607463   \n",
       "39623           0.000675                   0.003830   -0.430969   \n",
       "39624           0.000675                  -0.009415   -0.695709   \n",
       "39625           0.000675                   0.012916   -0.342723   \n",
       "39626           0.000675                   0.018080   -0.607463   \n",
       "39627           0.000675                   0.006850    0.186757   \n",
       "39628           0.000675                   0.021630   -0.607463   \n",
       "39629           0.000675                   0.010246   -0.607463   \n",
       "39630           0.000675                  -0.024354   -0.783956   \n",
       "39631           0.000675                   0.014296   -0.607463   \n",
       "39632           0.000675                  -0.008357    0.363251   \n",
       "39633           0.000675                  -0.022724   -0.077983   \n",
       "39634           0.000675                   0.029707    0.892731   \n",
       "39635           0.000675                  -0.014498    0.627991   \n",
       "39636           0.000675                  -0.068688    1.069224   \n",
       "39637           0.000675                  -0.025448    0.363251   \n",
       "39638           0.000675                   0.041835   -0.519216   \n",
       "39639           0.000675                  -0.001346   -0.166229   \n",
       "39640           0.000675                   0.059999   -0.166229   \n",
       "39641           0.000675                  -0.013798    1.157470   \n",
       "39642           0.000675                   0.001068   -0.077983   \n",
       "39643           0.000675                   0.048082   -0.872203   \n",
       "\n",
       "        num_self_hrefs   num_imgs   num_videos   ...     \\\n",
       "0            -0.335566  -0.426526    -0.304268   ...      \n",
       "1            -0.594963  -0.426526    -0.304268   ...      \n",
       "2            -0.594963  -0.426526    -0.304268   ...      \n",
       "3            -0.854360  -0.426526    -0.304268   ...      \n",
       "4             4.074185   1.860061    -0.304268   ...      \n",
       "5            -0.335566  -0.546872    -0.304268   ...      \n",
       "6             4.333583   1.860061    -0.304268   ...      \n",
       "7             4.333583   1.860061    -0.304268   ...      \n",
       "8            -0.854360  -0.546872    -0.304268   ...      \n",
       "9            -0.594963  -0.426526    -0.060829   ...      \n",
       "10           -0.854360  -0.426526    -0.304268   ...      \n",
       "11           -0.854360  -0.426526    -0.304268   ...      \n",
       "12           -0.335566   0.776941    -0.304268   ...      \n",
       "13           -0.335566  -0.546872     4.807953   ...      \n",
       "14           -0.076169   0.536248    -0.304268   ...      \n",
       "15           -0.854360  -0.426526    -0.304268   ...      \n",
       "16            3.814788   0.897288    -0.060829   ...      \n",
       "17           -0.854360  -0.426526    -0.304268   ...      \n",
       "18           -0.594963  -0.426526    -0.304268   ...      \n",
       "19            5.371171   4.507687    -0.304268   ...      \n",
       "20            4.074185   1.860061    -0.304268   ...      \n",
       "21           -0.335566  -0.426526    -0.060829   ...      \n",
       "22            4.333583   1.860061    -0.304268   ...      \n",
       "23           -0.594963  -0.426526    -0.304268   ...      \n",
       "24           -0.335566  -0.426526    -0.304268   ...      \n",
       "25           -0.335566  -0.426526    -0.304268   ...      \n",
       "26           -0.076169  -0.426526    -0.304268   ...      \n",
       "27            4.852377   2.822834    -0.304268   ...      \n",
       "28           -0.594963  -0.546872    -0.304268   ...      \n",
       "29           -0.594963  -0.426526    -0.304268   ...      \n",
       "...                ...        ...          ...   ...      \n",
       "39614        -0.335566  -0.306179    -0.304268   ...      \n",
       "39615        -0.854360   1.980408    -0.060829   ...      \n",
       "39616        -0.854360  -0.546872    -0.060829   ...      \n",
       "39617        -0.076169  -0.065486    -0.304268   ...      \n",
       "39618         1.480214  -0.426526    -0.304268   ...      \n",
       "39619        -0.594963  -0.426526    -0.304268   ...      \n",
       "39620        -0.335566  -0.426526    -0.304268   ...      \n",
       "39621        -0.594963  -0.426526    -0.304268   ...      \n",
       "39622        -0.594963   0.175208    -0.304268   ...      \n",
       "39623         0.702022  -0.306179    -0.304268   ...      \n",
       "39624        -0.076169  -0.185832    -0.304268   ...      \n",
       "39625         0.961420  -0.426526    -0.060829   ...      \n",
       "39626        -0.335566  -0.426526    -0.060829   ...      \n",
       "39627        -0.594963  -0.426526    -0.304268   ...      \n",
       "39628        -0.335566  -0.426526    -0.304268   ...      \n",
       "39629        -0.594963  -0.546872     0.182610   ...      \n",
       "39630        -0.335566  -0.306179    -0.060829   ...      \n",
       "39631        -0.594963  -0.426526    -0.304268   ...      \n",
       "39632        -0.335566  -0.185832    -0.304268   ...      \n",
       "39633        -0.854360  -0.426526    -0.304268   ...      \n",
       "39634         2.517803   0.536248     0.182610   ...      \n",
       "39635        -0.335566  -0.306179    -0.304268   ...      \n",
       "39636        -0.594963   0.656594    -0.304268   ...      \n",
       "39637         2.258405   0.175208    -0.304268   ...      \n",
       "39638        -0.076169  -0.426526    -0.304268   ...      \n",
       "39639         0.961420  -0.426526    -0.060829   ...      \n",
       "39640         0.961420  -0.185832    11.380809   ...      \n",
       "39641        -0.594963   0.897288    -0.060829   ...      \n",
       "39642        -0.594963  -0.426526    -0.304268   ...      \n",
       "39643        -0.594963  -0.546872     0.182610   ...      \n",
       "\n",
       "        min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                    0.063865               -0.228941               -0.708369   \n",
       "1                   -0.870968               -0.228941                1.102174   \n",
       "2                    0.063865                0.981798               -1.621797   \n",
       "3                    0.573773                0.174639               -0.862584   \n",
       "4                   -0.870968                0.981798                0.307944   \n",
       "5                    0.573773               -0.632520                0.505184   \n",
       "6                    0.063865                0.981798                0.274380   \n",
       "7                    0.063865                0.981798                0.131114   \n",
       "8                    4.270611                0.174639                1.053240   \n",
       "9                    0.063865               -1.036100                0.167775   \n",
       "10                   0.063865                0.981798               -1.217781   \n",
       "11                   1.466113               -0.228941               -0.023299   \n",
       "12                   1.466113               -0.228941               -0.398457   \n",
       "13                   0.905214                0.981798               -0.613547   \n",
       "14                   0.573773               -1.036100                0.946052   \n",
       "15                  -0.637259               -0.632520                0.308276   \n",
       "16                   0.063865                0.981798               -1.111087   \n",
       "17                  -0.870968                0.981798                0.899449   \n",
       "18                  -0.870968               -1.036100                1.053240   \n",
       "19                   0.063865                0.981798                0.256321   \n",
       "20                   0.063865                0.981798                0.414773   \n",
       "21                  -0.637259               -1.641469                1.183730   \n",
       "22                   0.063865                0.981798                0.229095   \n",
       "23                   0.063865               -0.632520                2.031912   \n",
       "24                   0.573773               -1.305153               -1.542053   \n",
       "25                   2.167238               -1.641469                1.118485   \n",
       "26                   0.063865                0.981798               -0.034173   \n",
       "27                  -0.637259                0.981798                0.448095   \n",
       "28                   0.573773               -0.632520                0.642198   \n",
       "29                  -0.870968                0.981798                0.357296   \n",
       "...                       ...                     ...                     ...   \n",
       "39614                0.063865               -0.632520                0.264865   \n",
       "39615               -1.338384               -3.053998                2.031912   \n",
       "39616               -1.338384               -3.053998                2.031912   \n",
       "39617               -0.637259                0.981798                0.553030   \n",
       "39618                0.063865                0.174639                0.694394   \n",
       "39619                0.063865               -0.228941               -0.093204   \n",
       "39620                0.063865               -1.036100               -2.078510   \n",
       "39621                0.063865               -1.036100               -0.179887   \n",
       "39622                0.063865                0.981798               -0.023299   \n",
       "39623                0.063865               -0.228941                0.033790   \n",
       "39624                0.998697               -0.027151                0.623823   \n",
       "39625                0.063865               -1.036100                1.472671   \n",
       "39626                0.573773                0.981798                0.890128   \n",
       "39627                0.063865               -0.632520               -0.512635   \n",
       "39628               -0.870968                0.174639               -2.339489   \n",
       "39629                1.466113                0.376429               -0.838859   \n",
       "39630               -0.461978                0.578218                0.740997   \n",
       "39631                0.063865                0.376429               -0.904104   \n",
       "39632                0.063865                0.174639                1.131534   \n",
       "39633               -0.637259                0.174639                0.612343   \n",
       "39634                2.167238                0.981798               -2.339489   \n",
       "39635               -0.870968                0.981798                0.281177   \n",
       "39636                0.063865                0.981798                0.218538   \n",
       "39637               -0.870968                0.981798               -1.331073   \n",
       "39638                1.666435                0.174639                0.074568   \n",
       "39639                0.063865               -0.027151               -0.003726   \n",
       "39640                0.573773               -0.228941                0.379044   \n",
       "39641                0.573773               -1.036100               -0.758786   \n",
       "39642               -0.461978               -1.036100                0.424968   \n",
       "39643                0.063865               -1.036100                0.466037   \n",
       "\n",
       "        min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                   -0.268895               -0.969886             0.671245   \n",
       "1                    1.367424                0.078642            -0.870807   \n",
       "2                   -0.957871               -0.270867            -0.870807   \n",
       "3                   -0.268895               -0.620377            -0.870807   \n",
       "4                    0.075594                0.602906             0.531059   \n",
       "5                    0.420082                0.078642             1.111832   \n",
       "6                    0.075594                0.602906            -0.870807   \n",
       "7                    0.075594                0.602906             2.213297   \n",
       "8                    1.367424               -0.183490            -0.485294   \n",
       "9                    0.075594                0.078642            -0.870807   \n",
       "10                  -1.646847                0.078642            -0.870807   \n",
       "11                   0.420082               -0.183490            -0.870807   \n",
       "12                  -0.268895                0.602906             2.213297   \n",
       "13                  -0.613383                0.078642             2.213297   \n",
       "14                   1.152119                0.602906             1.442271   \n",
       "15                  -0.268895                0.602906             1.442271   \n",
       "16                  -1.646847                0.602906             0.876852   \n",
       "17                   1.109058                0.078642            -0.870807   \n",
       "18                   1.367424               -0.183490             1.772711   \n",
       "19                   0.075594                0.602906             0.671245   \n",
       "20                   0.075594                0.602906            -0.870807   \n",
       "21                   1.223887                0.602906            -0.870807   \n",
       "22                   0.075594                0.602906            -0.870807   \n",
       "23                   1.798034                1.127170             0.517040   \n",
       "24                  -1.646847               -0.183490             1.288066   \n",
       "25                   1.109058                0.602906             1.904887   \n",
       "26                   0.075594               -0.183490            -0.870807   \n",
       "27                   0.075594                0.602906             0.671245   \n",
       "28                   0.721509               -0.183490            -0.870807   \n",
       "29                  -0.268895                0.078642             0.671245   \n",
       "...                       ...                     ...                  ...   \n",
       "39614                0.075594                0.602906            -0.870807   \n",
       "39615                1.798034                1.127170             0.531059   \n",
       "39616                1.798034                1.127170             0.531059   \n",
       "39617                0.075594                0.602906             0.531059   \n",
       "39618                0.936814               -0.183490            -0.485294   \n",
       "39619               -0.613383                0.078642            -0.870807   \n",
       "39620               -0.785627               -2.018414             1.133861   \n",
       "39621               -0.613383                0.078642            -0.870807   \n",
       "39622               -1.646847                0.078642             0.054425   \n",
       "39623                0.075594                0.078642             1.750682   \n",
       "39624                0.721509                0.865038            -0.870807   \n",
       "39625                1.551971                0.378222             1.596477   \n",
       "39626                1.223887               -0.183490            -0.870807   \n",
       "39627               -0.268895               -0.183490             0.909563   \n",
       "39628               -1.646847                0.078642            -0.870807   \n",
       "39629                0.075594                0.078642             2.213297   \n",
       "39630                0.649740                0.602906             0.601152   \n",
       "39631               -1.646847                0.602906             2.213297   \n",
       "39632                1.367424                0.078642             0.671245   \n",
       "39633                0.764570                0.602906            -0.870807   \n",
       "39634               -1.646847               -0.183490            -0.870807   \n",
       "39635                0.420082                0.602906            -0.562396   \n",
       "39636               -0.268895                0.602906            -0.870807   \n",
       "39637               -1.646847                0.602906             1.545075   \n",
       "39638                0.936814               -1.494150            -0.870807   \n",
       "39639                0.075594               -0.183490            -0.562396   \n",
       "39640                0.420082                0.078642             0.054425   \n",
       "39641               -0.957871               -0.620377             0.531059   \n",
       "39642                0.075594                0.996104            -0.870807   \n",
       "39643                1.109058               -0.969886             0.157228   \n",
       "\n",
       "        title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                      -0.975432                -1.810719   \n",
       "1                      -0.269076                 0.837749   \n",
       "2                      -0.269076                 0.837749   \n",
       "3                      -0.269076                 0.837749   \n",
       "4                       0.244637                -1.569949   \n",
       "5                       0.538188                -1.054014   \n",
       "6                      -0.269076                 0.837749   \n",
       "7                       1.614540                 0.837749   \n",
       "8                      -0.269076                 0.175632   \n",
       "9                      -0.269076                 0.837749   \n",
       "10                     -0.269076                 0.837749   \n",
       "11                     -0.269076                 0.837749   \n",
       "12                     -4.036308                 0.837749   \n",
       "13                     -4.036308                 0.837749   \n",
       "14                      1.802901                -0.486485   \n",
       "15                     -1.210884                -0.486485   \n",
       "16                     -0.645799                -1.457590   \n",
       "17                     -0.269076                 0.837749   \n",
       "18                     -2.959956                 0.081044   \n",
       "19                     -0.269076                -1.810719   \n",
       "20                     -0.269076                 0.837749   \n",
       "21                     -0.269076                 0.837749   \n",
       "22                     -0.269076                 0.837749   \n",
       "23                      1.237817                -1.545872   \n",
       "24                     -1.775969                -0.751332   \n",
       "25                      1.237817                 0.308055   \n",
       "26                     -0.269076                 0.837749   \n",
       "27                      1.614540                -1.810719   \n",
       "28                     -0.269076                 0.837749   \n",
       "29                      1.614540                -1.810719   \n",
       "...                          ...                      ...   \n",
       "39614                  -0.269076                 0.837749   \n",
       "39615                   0.244637                -1.569949   \n",
       "39616                   0.244637                -1.569949   \n",
       "39617                   0.244637                -1.569949   \n",
       "39618                  -0.739980                 0.175632   \n",
       "39619                  -0.269076                 0.837749   \n",
       "39620                  -0.269076                -1.016179   \n",
       "39621                  -0.269076                 0.837749   \n",
       "39622                   0.358796                -0.751332   \n",
       "39623                  -1.775969                 0.043208   \n",
       "39624                  -0.269076                 0.837749   \n",
       "39625                   1.237817                -0.221638   \n",
       "39626                  -0.269076                 0.837749   \n",
       "39627                  -0.765666                -1.401410   \n",
       "39628                  -0.269076                 0.837749   \n",
       "39629                  -2.152692                 0.837749   \n",
       "39630                   0.364504                -1.690334   \n",
       "39631                  -4.036308                 0.837749   \n",
       "39632                   1.614540                -1.810719   \n",
       "39633                  -0.269076                 0.837749   \n",
       "39634                  -0.269076                 0.837749   \n",
       "39635                  -0.269076                 0.308055   \n",
       "39636                  -0.269076                 0.837749   \n",
       "39637                  -2.529415                -0.309921   \n",
       "39638                  -0.269076                 0.837749   \n",
       "39639                  -0.269076                 0.308055   \n",
       "39640                   3.498156                -0.751332   \n",
       "39641                   0.244637                -1.569949   \n",
       "39642                  -0.269076                 0.837749   \n",
       "39643                   0.672732                -0.927896   \n",
       "\n",
       "        abs_title_sentiment_polarity   shares  \n",
       "0                           0.138920      593  \n",
       "1                          -0.689658      711  \n",
       "2                          -0.689658     1500  \n",
       "3                          -0.689658     1200  \n",
       "4                          -0.087056      505  \n",
       "5                           0.257288      855  \n",
       "6                          -0.689658      556  \n",
       "7                           1.519883      891  \n",
       "8                          -0.689658     3600  \n",
       "9                          -0.689658      710  \n",
       "10                         -0.689658     2200  \n",
       "11                         -0.689658     1900  \n",
       "12                          3.729424      823  \n",
       "13                          3.729424    10000  \n",
       "14                          1.740837      761  \n",
       "15                          0.415112     1600  \n",
       "16                         -0.247750    13600  \n",
       "17                         -0.689658     3100  \n",
       "18                          2.466829     5700  \n",
       "19                         -0.689658    17100  \n",
       "20                         -0.689658     2800  \n",
       "21                         -0.689658      598  \n",
       "22                         -0.689658      445  \n",
       "23                          1.077975     1500  \n",
       "24                          1.077975      852  \n",
       "25                          1.077975      783  \n",
       "26                         -0.689658     1500  \n",
       "27                          1.519883     1800  \n",
       "28                         -0.689658      462  \n",
       "29                          1.519883      425  \n",
       "...                              ...      ...  \n",
       "39614                      -0.689658     1400  \n",
       "39615                      -0.087056     5700  \n",
       "39616                      -0.087056     2100  \n",
       "39617                      -0.087056      691  \n",
       "39618                      -0.137273     1400  \n",
       "39619                      -0.689658     1200  \n",
       "39620                      -0.689658     2400  \n",
       "39621                      -0.689658    24300  \n",
       "39622                       0.046856     2900  \n",
       "39623                       1.077975      947  \n",
       "39624                      -0.689658     3200  \n",
       "39625                       1.077975     1400  \n",
       "39626                      -0.689658     1100  \n",
       "39627                      -0.107143     1200  \n",
       "39628                      -0.689658     1000  \n",
       "39629                       1.519883     2400  \n",
       "39630                       0.053551     1500  \n",
       "39631                       3.729424      914  \n",
       "39632                       1.519883     1700  \n",
       "39633                      -0.689658     1500  \n",
       "39634                      -0.689658     1000  \n",
       "39635                      -0.689658     1300  \n",
       "39636                      -0.689658     1700  \n",
       "39637                       1.961791     1400  \n",
       "39638                      -0.689658     1200  \n",
       "39639                      -0.689658     1800  \n",
       "39640                       3.729424     1900  \n",
       "39641                      -0.087056     1900  \n",
       "39642                      -0.689658     1100  \n",
       "39643                       0.415112     1300  \n",
       "\n",
       "[39644 rows x 60 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(df_std)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std['clusters'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050223</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.040313</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>-0.009308</td>\n",
       "      <td>-0.011210</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>-0.027450</td>\n",
       "      <td>0.248970</td>\n",
       "      <td>0.151720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063361</td>\n",
       "      <td>0.054657</td>\n",
       "      <td>-0.124137</td>\n",
       "      <td>-0.069198</td>\n",
       "      <td>-0.035754</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.077448</td>\n",
       "      <td>-0.003879</td>\n",
       "      <td>0.170501</td>\n",
       "      <td>16411.176363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099605</td>\n",
       "      <td>0.235478</td>\n",
       "      <td>-0.024881</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>-0.014761</td>\n",
       "      <td>0.068081</td>\n",
       "      <td>-0.317677</td>\n",
       "      <td>0.129559</td>\n",
       "      <td>0.115454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071671</td>\n",
       "      <td>-0.180233</td>\n",
       "      <td>-0.349726</td>\n",
       "      <td>-0.136742</td>\n",
       "      <td>-0.553086</td>\n",
       "      <td>0.310305</td>\n",
       "      <td>0.091212</td>\n",
       "      <td>0.179091</td>\n",
       "      <td>0.449167</td>\n",
       "      <td>187668.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.660575</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>0.590783</td>\n",
       "      <td>-0.013493</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.017897</td>\n",
       "      <td>0.686822</td>\n",
       "      <td>0.312927</td>\n",
       "      <td>0.355728</td>\n",
       "      <td>0.385476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520405</td>\n",
       "      <td>0.309165</td>\n",
       "      <td>-0.582519</td>\n",
       "      <td>-0.223441</td>\n",
       "      <td>-0.445622</td>\n",
       "      <td>-0.544038</td>\n",
       "      <td>-0.278046</td>\n",
       "      <td>0.339585</td>\n",
       "      <td>-0.258272</td>\n",
       "      <td>651516.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147082</td>\n",
       "      <td>0.219740</td>\n",
       "      <td>-0.087360</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.007539</td>\n",
       "      <td>-0.004693</td>\n",
       "      <td>0.383244</td>\n",
       "      <td>-0.057930</td>\n",
       "      <td>0.268288</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121846</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>-0.316316</td>\n",
       "      <td>-0.235496</td>\n",
       "      <td>-0.146392</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.167739</td>\n",
       "      <td>-0.013156</td>\n",
       "      <td>0.265737</td>\n",
       "      <td>63294.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002121</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>-0.016628</td>\n",
       "      <td>-0.010150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004420</td>\n",
       "      <td>-0.003633</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>-0.011450</td>\n",
       "      <td>-0.005730</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.012153</td>\n",
       "      <td>1970.031100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "clusters                                                                     \n",
       "0           0.050223        -0.009419          -0.040313         -0.006771   \n",
       "1           0.099605         0.235478          -0.024881         -0.007413   \n",
       "2           0.660575         0.126734           0.590783         -0.013493   \n",
       "3          -0.147082         0.219740          -0.087360         -0.000388   \n",
       "4          -0.002121        -0.001164           0.002893          0.000408   \n",
       "\n",
       "           n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "clusters                                                             \n",
       "0                 -0.009308                  -0.011210    0.206687   \n",
       "1                 -0.019100                  -0.014761    0.068081   \n",
       "2                  0.000675                  -0.017897    0.686822   \n",
       "3                 -0.007539                  -0.004693    0.383244   \n",
       "4                  0.000613                   0.000705   -0.014942   \n",
       "\n",
       "           num_self_hrefs   num_imgs   num_videos      ...        \\\n",
       "clusters                                               ...         \n",
       "0               -0.027450   0.248970     0.151720      ...         \n",
       "1               -0.317677   0.129559     0.115454      ...         \n",
       "2                0.312927   0.355728     0.385476      ...         \n",
       "3               -0.057930   0.268288     0.157886      ...         \n",
       "4                0.002208  -0.016628    -0.010150      ...         \n",
       "\n",
       "           min_positive_polarity   max_positive_polarity  \\\n",
       "clusters                                                   \n",
       "0                       0.063361                0.054657   \n",
       "1                      -0.071671               -0.180233   \n",
       "2                      -0.520405                0.309165   \n",
       "3                       0.121846                0.074532   \n",
       "4                      -0.004420               -0.003633   \n",
       "\n",
       "           avg_negative_polarity   min_negative_polarity  \\\n",
       "clusters                                                   \n",
       "0                      -0.124137               -0.069198   \n",
       "1                      -0.349726               -0.136742   \n",
       "2                      -0.582519               -0.223441   \n",
       "3                      -0.316316               -0.235496   \n",
       "4                       0.009836                0.005829   \n",
       "\n",
       "           max_negative_polarity   title_subjectivity  \\\n",
       "clusters                                                \n",
       "0                      -0.035754             0.168787   \n",
       "1                      -0.553086             0.310305   \n",
       "2                      -0.445622            -0.544038   \n",
       "3                      -0.146392             0.200831   \n",
       "4                       0.003612            -0.011450   \n",
       "\n",
       "           title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "clusters                                                       \n",
       "0                          0.077448                -0.003879   \n",
       "1                          0.091212                 0.179091   \n",
       "2                         -0.278046                 0.339585   \n",
       "3                          0.167739                -0.013156   \n",
       "4                         -0.005730                 0.000124   \n",
       "\n",
       "           abs_title_sentiment_polarity         shares  \n",
       "clusters                                                \n",
       "0                              0.170501   16411.176363  \n",
       "1                              0.449167  187668.965517  \n",
       "2                             -0.258272  651516.666667  \n",
       "3                              0.265737   63294.132812  \n",
       "4                             -0.012153    1970.031100  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.groupby(['clusters']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.613414</td>\n",
       "      <td>-3.026830</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>-5.797463</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-9.358111</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.478002</td>\n",
       "      <td>-1.607726</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>-5.014526</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-8.309583</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-2.906139</td>\n",
       "      <td>-1.569949</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.376028</td>\n",
       "      <td>-1.134691</td>\n",
       "      <td>-0.875639</td>\n",
       "      <td>-0.088196</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.097429</td>\n",
       "      <td>-0.872203</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.060829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>-1.036100</td>\n",
       "      <td>-3.448651</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-3.066942</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-1.399246</td>\n",
       "      <td>-1.621543</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.608745</td>\n",
       "      <td>-2.553795</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>-5.014526</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-8.309583</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.618083</td>\n",
       "      <td>-3.972899</td>\n",
       "      <td>-1.160078</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.190487</td>\n",
       "      <td>-0.211094</td>\n",
       "      <td>-0.960449</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.546872</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338384</td>\n",
       "      <td>-3.053998</td>\n",
       "      <td>-5.797463</td>\n",
       "      <td>-1.646847</td>\n",
       "      <td>-9.358111</td>\n",
       "      <td>-0.870807</td>\n",
       "      <td>-4.036308</td>\n",
       "      <td>-1.810719</td>\n",
       "      <td>-0.689658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "clusters                                                                     \n",
       "0          -1.613414        -3.026830          -1.160078         -0.155714   \n",
       "1          -1.478002        -1.607726          -1.160078         -0.155714   \n",
       "2          -0.376028        -1.134691          -0.875639         -0.088196   \n",
       "3          -1.608745        -2.553795          -1.160078         -0.155714   \n",
       "4          -1.618083        -3.972899          -1.160078         -0.155714   \n",
       "\n",
       "           n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "clusters                                                             \n",
       "0                 -0.190487                  -0.211094   -0.960449   \n",
       "1                 -0.190487                  -0.211094   -0.960449   \n",
       "2                  0.000675                  -0.097429   -0.872203   \n",
       "3                 -0.190487                  -0.211094   -0.960449   \n",
       "4                 -0.190487                  -0.211094   -0.960449   \n",
       "\n",
       "           num_self_hrefs   num_imgs   num_videos   ...     \\\n",
       "clusters                                            ...      \n",
       "0               -0.854360  -0.546872    -0.304268   ...      \n",
       "1               -0.854360  -0.546872    -0.304268   ...      \n",
       "2               -0.594963  -0.546872    -0.060829   ...      \n",
       "3               -0.854360  -0.546872    -0.304268   ...      \n",
       "4               -0.854360  -0.546872    -0.304268   ...      \n",
       "\n",
       "           min_positive_polarity   max_positive_polarity  \\\n",
       "clusters                                                   \n",
       "0                      -1.338384               -3.053998   \n",
       "1                      -1.338384               -3.053998   \n",
       "2                      -0.870968               -1.036100   \n",
       "3                      -1.338384               -3.053998   \n",
       "4                      -1.338384               -3.053998   \n",
       "\n",
       "           avg_negative_polarity   min_negative_polarity  \\\n",
       "clusters                                                   \n",
       "0                      -5.797463               -1.646847   \n",
       "1                      -5.014526               -1.646847   \n",
       "2                      -3.448651               -1.646847   \n",
       "3                      -5.014526               -1.646847   \n",
       "4                      -5.797463               -1.646847   \n",
       "\n",
       "           max_negative_polarity   title_subjectivity  \\\n",
       "clusters                                                \n",
       "0                      -9.358111            -0.870807   \n",
       "1                      -8.309583            -0.870807   \n",
       "2                      -3.066942            -0.870807   \n",
       "3                      -8.309583            -0.870807   \n",
       "4                      -9.358111            -0.870807   \n",
       "\n",
       "           title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "clusters                                                       \n",
       "0                         -4.036308                -1.810719   \n",
       "1                         -2.906139                -1.569949   \n",
       "2                         -1.399246                -1.621543   \n",
       "3                         -4.036308                -1.810719   \n",
       "4                         -4.036308                -1.810719   \n",
       "\n",
       "           abs_title_sentiment_polarity   shares  \n",
       "clusters                                          \n",
       "0                             -0.689658     9200  \n",
       "1                             -0.689658   128500  \n",
       "2                             -0.689658   441000  \n",
       "3                             -0.689658    39900  \n",
       "4                             -0.689658        1  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.groupby(['clusters']).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>3.122620</td>\n",
       "      <td>16.827550</td>\n",
       "      <td>0.128324</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.095206</td>\n",
       "      <td>12.453042</td>\n",
       "      <td>13.671880</td>\n",
       "      <td>12.811607</td>\n",
       "      <td>21.848691</td>\n",
       "      <td>...</td>\n",
       "      <td>12.684102</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>3.498156</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>39800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.515072</td>\n",
       "      <td>2.649586</td>\n",
       "      <td>6.937963</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.073327</td>\n",
       "      <td>4.246103</td>\n",
       "      <td>1.220817</td>\n",
       "      <td>1.980408</td>\n",
       "      <td>3.590758</td>\n",
       "      <td>...</td>\n",
       "      <td>2.167238</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>3.498156</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.505734</td>\n",
       "      <td>1.230482</td>\n",
       "      <td>4.339797</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>1.510457</td>\n",
       "      <td>1.999008</td>\n",
       "      <td>1.619368</td>\n",
       "      <td>2.373562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.906439</td>\n",
       "      <td>1.152119</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>0.781392</td>\n",
       "      <td>0.807276</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>0.636066</td>\n",
       "      <td>843300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.715856</td>\n",
       "      <td>4.068690</td>\n",
       "      <td>7.519579</td>\n",
       "      <td>0.087747</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.084266</td>\n",
       "      <td>12.100056</td>\n",
       "      <td>7.965143</td>\n",
       "      <td>6.072194</td>\n",
       "      <td>6.268588</td>\n",
       "      <td>...</td>\n",
       "      <td>7.075108</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>3.498156</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.757880</td>\n",
       "      <td>5.960828</td>\n",
       "      <td>15.320444</td>\n",
       "      <td>198.954458</td>\n",
       "      <td>199.000326</td>\n",
       "      <td>198.883779</td>\n",
       "      <td>25.866534</td>\n",
       "      <td>29.235709</td>\n",
       "      <td>14.857501</td>\n",
       "      <td>17.953666</td>\n",
       "      <td>...</td>\n",
       "      <td>12.684102</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>2.031912</td>\n",
       "      <td>1.798034</td>\n",
       "      <td>1.127170</td>\n",
       "      <td>2.213297</td>\n",
       "      <td>3.498156</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>3.729424</td>\n",
       "      <td>9100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "clusters                                                                     \n",
       "0           1.757880         3.122620          16.827550          0.128324   \n",
       "1           1.515072         2.649586           6.937963          0.063100   \n",
       "2           1.505734         1.230482           4.339797          0.040100   \n",
       "3           1.715856         4.068690           7.519579          0.087747   \n",
       "4           1.757880         5.960828          15.320444        198.954458   \n",
       "\n",
       "           n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "clusters                                                             \n",
       "0                  0.000675                   0.095206   12.453042   \n",
       "1                  0.000675                   0.073327    4.246103   \n",
       "2                  0.000675                   0.049828    1.510457   \n",
       "3                  0.000675                   0.084266   12.100056   \n",
       "4                199.000326                 198.883779   25.866534   \n",
       "\n",
       "           num_self_hrefs   num_imgs   num_videos   ...     \\\n",
       "clusters                                            ...      \n",
       "0               13.671880  12.811607    21.848691   ...      \n",
       "1                1.220817   1.980408     3.590758   ...      \n",
       "2                1.999008   1.619368     2.373562   ...      \n",
       "3                7.965143   6.072194     6.268588   ...      \n",
       "4               29.235709  14.857501    17.953666   ...      \n",
       "\n",
       "           min_positive_polarity   max_positive_polarity  \\\n",
       "clusters                                                   \n",
       "0                      12.684102                0.981798   \n",
       "1                       2.167238                0.981798   \n",
       "2                       0.063865                0.981798   \n",
       "3                       7.075108                0.981798   \n",
       "4                      12.684102                0.981798   \n",
       "\n",
       "           avg_negative_polarity   min_negative_polarity  \\\n",
       "clusters                                                   \n",
       "0                       2.031912                1.798034   \n",
       "1                       2.031912                1.798034   \n",
       "2                       0.906439                1.152119   \n",
       "3                       2.031912                1.798034   \n",
       "4                       2.031912                1.798034   \n",
       "\n",
       "           max_negative_polarity   title_subjectivity  \\\n",
       "clusters                                                \n",
       "0                       1.127170             2.213297   \n",
       "1                       1.127170             2.213297   \n",
       "2                       0.602906             0.781392   \n",
       "3                       1.127170             2.213297   \n",
       "4                       1.127170             2.213297   \n",
       "\n",
       "           title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "clusters                                                       \n",
       "0                          3.498156                 0.837749   \n",
       "1                          3.498156                 0.837749   \n",
       "2                          0.807276                 0.837749   \n",
       "3                          3.498156                 0.837749   \n",
       "4                          3.498156                 0.837749   \n",
       "\n",
       "           abs_title_sentiment_polarity   shares  \n",
       "clusters                                          \n",
       "0                              3.729424    39800  \n",
       "1                              3.729424   310800  \n",
       "2                              0.636066   843300  \n",
       "3                              3.729424   122800  \n",
       "4                              3.729424     9100  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.groupby(['clusters']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster details\n",
    "0 - > (9200,39800)\n",
    "1 - > (128500,310800)\n",
    "2 - > (441000,843300)\n",
    "3 - > (39900,122800)\n",
    "4 - > (1,9100)\n",
    "\n",
    "4 - > (1,9100)           very low\n",
    "0 - > (9200,39800)       low\n",
    "3 - > (39900,122800)     medium\n",
    "1 - > (128500,310800)    high\n",
    "2 - > (441000,843300)    very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df_std.drop(' shares', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 60)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_std.iloc[:,0:59]\n",
    "y = df_std.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 59)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " y = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta = X.values\n",
    "y_boruta = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t59\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t3\n",
      "Rejected: \t7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/boruta/boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t9 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t3\n",
      "Rejected: \t7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/boruta/boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t10 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t3\n",
      "Rejected: \t7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/boruta/boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t11 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t3\n",
      "Rejected: \t7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/boruta/boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t12 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t2\n",
      "Rejected: \t7\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t0\n",
      "Rejected: \t9\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t0\n",
      "Rejected: \t9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/boruta/boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(alpha=0.05,\n",
       "     estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=6, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=169, n_jobs=4, oob_score=False,\n",
       "            random_state=<mtrand.RandomState object at 0x1082aa1b0>,\n",
       "            verbose=0, warm_start=False),\n",
       "     max_iter=100, n_estimators='auto', perc=100,\n",
       "     random_state=<mtrand.RandomState object at 0x1082aa1b0>,\n",
       "     two_step=True, verbose=2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, n_jobs=4, class_weight='balanced', max_depth=6)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
    "boruta_selector.fit(X_boruta, y_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print (boruta_selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  5  6  7  8 10  4  8  3  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  2  1]\n"
     ]
    }
   ],
   "source": [
    "print (boruta_selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False False False False False False\n",
      " False False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True]\n"
     ]
    }
   ],
   "source": [
    "print (boruta_selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(X.columns.tolist(),columns=['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['rank']=boruta_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " min_positive_polarity, max_positive_polarity, avg_negative_polarity, min_negative_polarity, max_negative_polarity, title_subjectivity, title_sentiment_polarity, abs_title_subjectivity, abs_title_sentiment_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 50 features:\n",
      "                          features  rank\n",
      "0                        timedelta     1\n",
      "1                   n_tokens_title     1\n",
      "2                 n_tokens_content     1\n",
      "3                  n_unique_tokens     1\n",
      "4                 n_non_stop_words     1\n",
      "5         n_non_stop_unique_tokens     1\n",
      "6                        num_hrefs     1\n",
      "7                   num_self_hrefs     1\n",
      "8                         num_imgs     1\n",
      "9                       num_videos     1\n",
      "10            average_token_length     1\n",
      "11                    num_keywords     1\n",
      "12       data_channel_is_lifestyle     1\n",
      "13   data_channel_is_entertainment     1\n",
      "14             data_channel_is_bus     1\n",
      "15          data_channel_is_socmed     1\n",
      "16            data_channel_is_tech     1\n",
      "17           data_channel_is_world     1\n",
      "18                      kw_min_min     1\n",
      "19                      kw_max_min     1\n",
      "20                      kw_avg_min     1\n",
      "21                      kw_min_max     1\n",
      "22                      kw_max_max     1\n",
      "23                      kw_avg_max     1\n",
      "24                      kw_min_avg     1\n",
      "25                      kw_max_avg     1\n",
      "26                      kw_avg_avg     1\n",
      "27       self_reference_min_shares     1\n",
      "28       self_reference_max_shares     1\n",
      "29      self_reference_avg_sharess     1\n",
      "30               weekday_is_monday     5\n",
      "31              weekday_is_tuesday     6\n",
      "32            weekday_is_wednesday     7\n",
      "33             weekday_is_thursday     8\n",
      "34               weekday_is_friday    10\n",
      "35             weekday_is_saturday     4\n",
      "36               weekday_is_sunday     8\n",
      "37                      is_weekend     3\n",
      "38                          LDA_00     1\n",
      "39                          LDA_01     1\n",
      "40                          LDA_02     1\n",
      "41                          LDA_03     1\n",
      "42                          LDA_04     1\n",
      "43             global_subjectivity     1\n",
      "44       global_sentiment_polarity     1\n",
      "45      global_rate_positive_words     1\n",
      "46      global_rate_negative_words     1\n",
      "47             rate_positive_words     1\n",
      "48             rate_negative_words     1\n",
      "49           avg_positive_polarity     1\n"
     ]
    }
   ],
   "source": [
    "print ('\\n Top %d features:' % boruta_selector.n_features_)\n",
    "print (feature_df.head(boruta_selector.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.drop([' min_positive_polarity', ' max_positive_polarity', ' avg_negative_polarity', ' min_negative_polarity', ' max_negative_polarity',' title_subjectivity', ' title_sentiment_polarity', ' abs_title_subjectivity', ' abs_title_sentiment_polarity'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 50)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url\n",
       "http://mashable.com/2013/01/07/amazon-instant-video-browser/                             1\n",
       "http://mashable.com/2013/01/07/ap-samsung-sponsored-tweets/                              3\n",
       "http://mashable.com/2013/01/07/apple-40-billion-app-downloads/                           3\n",
       "http://mashable.com/2013/01/07/astronaut-notre-dame-bcs/                                 1\n",
       "http://mashable.com/2013/01/07/att-u-verse-apps/                                         4\n",
       "http://mashable.com/2013/01/07/beewi-smart-toys/                                         4\n",
       "http://mashable.com/2013/01/07/bodymedia-armbandgets-update/                             4\n",
       "http://mashable.com/2013/01/07/canon-poweshot-n/                                         4\n",
       "http://mashable.com/2013/01/07/car-of-the-future-infographic/                            4\n",
       "http://mashable.com/2013/01/07/chuck-hagel-website/                                      0\n",
       "http://mashable.com/2013/01/07/cosmic-events-doomsday/                                   0\n",
       "http://mashable.com/2013/01/07/crayon-creatures/                                         4\n",
       "http://mashable.com/2013/01/07/creature-cups/                                            4\n",
       "http://mashable.com/2013/01/07/dad-jokes/                                                1\n",
       "http://mashable.com/2013/01/07/downton-abbey-tumblrs/                                    4\n",
       "http://mashable.com/2013/01/07/earth-size-planets-milky-way/                             0\n",
       "http://mashable.com/2013/01/07/echo-game/                                                1\n",
       "http://mashable.com/2013/01/07/entrepreneur-trends-2013/                                 3\n",
       "http://mashable.com/2013/01/07/facebook-sick-app/                                        4\n",
       "http://mashable.com/2013/01/07/felt-audio-pulse-speaker/                                 4\n",
       "http://mashable.com/2013/01/07/ford-glympse/                                             4\n",
       "http://mashable.com/2013/01/07/ftc-google-leaks/                                         0\n",
       "http://mashable.com/2013/01/07/fujifilm-50x-superzoom/                                   4\n",
       "http://mashable.com/2013/01/07/hillary-clinton-helmet/                                   0\n",
       "http://mashable.com/2013/01/07/htc-q1/                                                   3\n",
       "http://mashable.com/2013/01/07/huawei-ascend-mate/                                       4\n",
       "http://mashable.com/2013/01/07/iheartradio-app-perfect-for/                              4\n",
       "http://mashable.com/2013/01/07/intel-awesome-laptop/                                     4\n",
       "http://mashable.com/2013/01/07/isp02-iphone-take-your-pulse/                             4\n",
       "http://mashable.com/2013/01/07/jobs-contently/                                           3\n",
       "                                                                                        ..\n",
       "http://mashable.com/2014/12/26/the-interview-is-a-hit-on-torrent-sites/                  0\n",
       "http://mashable.com/2014/12/26/toothpaste-fluorine-space/                                2\n",
       "http://mashable.com/2014/12/26/top-photography-series-2014/                              2\n",
       "http://mashable.com/2014/12/26/tor-attacked-lizard-squad/                                0\n",
       "http://mashable.com/2014/12/26/tsa-gift-wrap-regulations/                                0\n",
       "http://mashable.com/2014/12/26/tsunami-10-year-anniversary/                              0\n",
       "http://mashable.com/2014/12/26/turkey-teen-insult-erdogan/                               0\n",
       "http://mashable.com/2014/12/26/ukraine-prisoner-swap/                                    1\n",
       "http://mashable.com/2014/12/26/wacky-kickstarter-projects-2014/                          0\n",
       "http://mashable.com/2014/12/26/what-is-tor/                                              4\n",
       "http://mashable.com/2014/12/27/air-asia-flight-qz8501/                                   4\n",
       "http://mashable.com/2014/12/27/als-ice-bucket-challenge-swim/                            4\n",
       "http://mashable.com/2014/12/27/christmas-tree-bugs/                                      4\n",
       "http://mashable.com/2014/12/27/extremist-leader-surrenders-somalia/                      0\n",
       "http://mashable.com/2014/12/27/facebook-year-in-review/                                  0\n",
       "http://mashable.com/2014/12/27/frozen-doll-prank/                                        1\n",
       "http://mashable.com/2014/12/27/high-school-i-cant-breathe/                               0\n",
       "http://mashable.com/2014/12/27/japan-elderly-dementia/                                   0\n",
       "http://mashable.com/2014/12/27/las-vegas-new-years/                                      0\n",
       "http://mashable.com/2014/12/27/lbj-adviser-slams-selma/                                  0\n",
       "http://mashable.com/2014/12/27/music-grid-outfits/                                       1\n",
       "http://mashable.com/2014/12/27/nike-marc-newson/                                         3\n",
       "http://mashable.com/2014/12/27/north-korea-internet-outage-2/                            4\n",
       "http://mashable.com/2014/12/27/nypd-rafael-ramos-funeral/                                1\n",
       "http://mashable.com/2014/12/27/protests-continue-ramos-funeral/                          3\n",
       "http://mashable.com/2014/12/27/samsung-app-autism/                                       4\n",
       "http://mashable.com/2014/12/27/seth-rogen-james-franco-will-live-tweet-the-interview/    1\n",
       "http://mashable.com/2014/12/27/son-pays-off-mortgage/                                    1\n",
       "http://mashable.com/2014/12/27/ukraine-blasts/                                           0\n",
       "http://mashable.com/2014/12/27/youtube-channels-2015/                                    1\n",
       "Name: clusters, Length: 39644, dtype: int32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3899\n",
      "TrueNegative_test  7872\n",
      "FlasePositive_test  61\n",
      "FalseNegative_test  62\n",
      "logistic done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3022\n",
      "TrueNegative_test  7700\n",
      "FlasePositive_test  111\n",
      "FalseNegative_test  1061\n",
      "naive bayers done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3902\n",
      "TrueNegative_test  7892\n",
      "FlasePositive_test  48\n",
      "FalseNegative_test  52\n",
      "svm done\n",
      "TruePositive_test  3791\n",
      "TrueNegative_test  7655\n",
      "FlasePositive_test  204\n",
      "FalseNegative_test  244\n",
      "decision tree done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3632\n",
      "TrueNegative_test  7585\n",
      "FlasePositive_test  118\n",
      "FalseNegative_test  559\n",
      "ada done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3779\n",
      "TrueNegative_test  7717\n",
      "FlasePositive_test  138\n",
      "FalseNegative_test  260\n",
      "random done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3757\n",
      "TrueNegative_test  7695\n",
      "FlasePositive_test  136\n",
      "FalseNegative_test  306\n",
      "knn done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3903\n",
      "TrueNegative_test  7927\n",
      "FlasePositive_test  23\n",
      "FalseNegative_test  41\n",
      "nn done\n"
     ]
    }
   ],
   "source": [
    "b = all_classification_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuract with cv</th>\n",
       "      <th>Deviation(+/-)</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.984596</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>0.980329</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>59.915945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901463</td>\n",
       "      <td>0.837583</td>\n",
       "      <td>NaiveBayers</td>\n",
       "      <td>0.964571</td>\n",
       "      <td>0.740142</td>\n",
       "      <td>0.985789</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.267706</td>\n",
       "      <td>0.594845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991592</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>0.986849</td>\n",
       "      <td>0.993955</td>\n",
       "      <td>0.986054</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>70.854863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962334</td>\n",
       "      <td>0.944209</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.948936</td>\n",
       "      <td>0.939529</td>\n",
       "      <td>0.974042</td>\n",
       "      <td>0.913538</td>\n",
       "      <td>0.293186</td>\n",
       "      <td>11.475771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943081</td>\n",
       "      <td>0.914746</td>\n",
       "      <td>AdaptiveBoosting</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.866619</td>\n",
       "      <td>0.984681</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>120.104881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966538</td>\n",
       "      <td>0.949975</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.964769</td>\n",
       "      <td>0.935628</td>\n",
       "      <td>0.982432</td>\n",
       "      <td>0.934841</td>\n",
       "      <td>0.186817</td>\n",
       "      <td>208.617432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>K-NearestNeighbours</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.924686</td>\n",
       "      <td>0.982633</td>\n",
       "      <td>0.957023</td>\n",
       "      <td>0.048928</td>\n",
       "      <td>311.620027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994619</td>\n",
       "      <td>0.991868</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.994142</td>\n",
       "      <td>0.989604</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>0.987947</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>48.023995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_score                 Model  Precision    Recall  Specificity  \\\n",
       "0  0.989659  0.984472    LogisticRegression   0.984596  0.984347     0.992311   \n",
       "0  0.901463  0.837583           NaiveBayers   0.964571  0.740142     0.985789   \n",
       "0  0.991592  0.987348  SupportVectorMachine   0.987848  0.986849     0.993955   \n",
       "0  0.962334  0.944209          DecisionTree   0.948936  0.939529     0.974042   \n",
       "0  0.943081  0.914746      AdaptiveBoosting   0.968533  0.866619     0.984681   \n",
       "0  0.966538  0.949975          RandomForest   0.964769  0.935628     0.982432   \n",
       "0  0.962838  0.944444   K-NearestNeighbours   0.965066  0.924686     0.982633   \n",
       "0  0.994619  0.991868         NeuralNetwork   0.994142  0.989604     0.997107   \n",
       "\n",
       "   Accuract with cv  Deviation(+/-)        time  \n",
       "0          0.980329        0.038236   59.915945  \n",
       "0          0.869646        0.267706    0.594845  \n",
       "0          0.986054        0.025660   70.854863  \n",
       "0          0.913538        0.293186   11.475771  \n",
       "0          0.750581        0.281553  120.104881  \n",
       "0          0.934841        0.186817  208.617432  \n",
       "0          0.957023        0.048928  311.620027  \n",
       "0          0.987947        0.037783   48.023995  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "# create the RFE model for the svm classifier \n",
    "# and select attributes\n",
    "rfe = RFE(svm, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "rfe = rfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 36 46  1  1  1 35 31 19 20 13 21 27 11  9 14  3  2 45 52 48 43 18 28\n",
      " 33 32 10 40 39 25 54 47 53 55 57 51 56 42  4 17  8 16  5 12 38 24 22  6\n",
      "  7 23 34 41 15 29 37 44 50 49 30]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',' data_channel_is_tech',\n",
    "       ' data_channel_is_world',\n",
    "    ' LDA_00',' LDA_04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',' data_channel_is_tech',\n",
    "       ' data_channel_is_world',\n",
    "    \n",
    "    \n",
    "    ' rate_positive_words',\n",
    "       ' rate_negative_words',' LDA_00'\n",
    "    ' LDA_02'\n",
    "    ' LDA_04',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' timedelta', ' n_tokens_title', ' n_tokens_content',\n",
       "       ' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',\n",
       "       ' num_hrefs', ' num_self_hrefs', ' num_imgs', ' num_videos',\n",
       "       ' average_token_length', ' num_keywords', ' data_channel_is_lifestyle',\n",
       "       ' data_channel_is_entertainment', ' data_channel_is_bus',\n",
       "       ' data_channel_is_socmed', ' data_channel_is_tech',\n",
       "       ' data_channel_is_world', ' kw_min_min', ' kw_max_min', ' kw_avg_min',\n",
       "       ' kw_min_max', ' kw_max_max', ' kw_avg_max', ' kw_min_avg',\n",
       "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
       "       ' self_reference_max_shares', ' self_reference_avg_sharess',\n",
       "       ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday',\n",
       "       ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday',\n",
       "       ' weekday_is_sunday', ' is_weekend', ' LDA_00', ' LDA_01', ' LDA_02',\n",
       "       ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
       "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
       "       ' global_rate_negative_words', ' rate_positive_words',\n",
       "       ' rate_negative_words', ' avg_positive_polarity',\n",
       "       ' min_positive_polarity', ' max_positive_polarity',\n",
       "       ' avg_negative_polarity', ' min_negative_polarity',\n",
       "       ' max_negative_polarity', ' title_subjectivity',\n",
       "       ' title_sentiment_polarity', ' abs_title_subjectivity',\n",
       "       ' abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[[' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',' data_channel_is_entertainment', ' data_channel_is_bus',\n",
    "       ' data_channel_is_socmed', ' data_channel_is_tech',\n",
    "       ' data_channel_is_world',' self_reference_min_shares',' avg_negative_polarity',' rate_positive_words',\n",
    "       ' rate_negative_words',' LDA_03', ' LDA_04', ' global_subjectivity',' LDA_00', ' LDA_01', ' LDA_02']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3778\n",
      "TrueNegative_test  7731\n",
      "FlasePositive_test  153\n",
      "FalseNegative_test  232\n",
      "logistic done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  2908\n",
      "TrueNegative_test  7711\n",
      "FlasePositive_test  83\n",
      "FalseNegative_test  1192\n",
      "naive bayers done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3786\n",
      "TrueNegative_test  7728\n",
      "FlasePositive_test  158\n",
      "FalseNegative_test  222\n",
      "svm done\n",
      "TruePositive_test  3773\n",
      "TrueNegative_test  7647\n",
      "FlasePositive_test  194\n",
      "FalseNegative_test  280\n",
      "decision tree done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3586\n",
      "TrueNegative_test  7263\n",
      "FlasePositive_test  429\n",
      "FalseNegative_test  616\n",
      "ada done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3776\n",
      "TrueNegative_test  7661\n",
      "FlasePositive_test  196\n",
      "FalseNegative_test  261\n",
      "random done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3786\n",
      "TrueNegative_test  7714\n",
      "FlasePositive_test  171\n",
      "FalseNegative_test  223\n",
      "knn done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  3813\n",
      "TrueNegative_test  7723\n",
      "FlasePositive_test  164\n",
      "FalseNegative_test  194\n",
      "nn done\n"
     ]
    }
   ],
   "source": [
    "b = all_classification_model(X2,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuract with cv</th>\n",
       "      <th>Deviation(+/-)</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967631</td>\n",
       "      <td>0.951517</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.961079</td>\n",
       "      <td>0.942145</td>\n",
       "      <td>0.980594</td>\n",
       "      <td>0.965496</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>26.088325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892803</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>NaiveBayers</td>\n",
       "      <td>0.972250</td>\n",
       "      <td>0.709268</td>\n",
       "      <td>0.989351</td>\n",
       "      <td>0.898476</td>\n",
       "      <td>0.047940</td>\n",
       "      <td>0.261091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968051</td>\n",
       "      <td>0.952213</td>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>0.959939</td>\n",
       "      <td>0.944611</td>\n",
       "      <td>0.979964</td>\n",
       "      <td>0.965572</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>26.565346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960148</td>\n",
       "      <td>0.940898</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.951097</td>\n",
       "      <td>0.930915</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>0.955507</td>\n",
       "      <td>0.028288</td>\n",
       "      <td>4.076963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912141</td>\n",
       "      <td>0.872825</td>\n",
       "      <td>AdaptiveBoosting</td>\n",
       "      <td>0.893151</td>\n",
       "      <td>0.853403</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>0.792513</td>\n",
       "      <td>0.195135</td>\n",
       "      <td>54.658319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961577</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.950655</td>\n",
       "      <td>0.935348</td>\n",
       "      <td>0.975054</td>\n",
       "      <td>0.959998</td>\n",
       "      <td>0.031809</td>\n",
       "      <td>54.048197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966874</td>\n",
       "      <td>0.950540</td>\n",
       "      <td>K-NearestNeighbours</td>\n",
       "      <td>0.956785</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.978313</td>\n",
       "      <td>0.964361</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>28.367278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969901</td>\n",
       "      <td>0.955160</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>0.951585</td>\n",
       "      <td>0.979206</td>\n",
       "      <td>0.966883</td>\n",
       "      <td>0.026363</td>\n",
       "      <td>45.740651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_score                 Model  Precision    Recall  Specificity  \\\n",
       "0  0.967631  0.951517    LogisticRegression   0.961079  0.942145     0.980594   \n",
       "0  0.892803  0.820195           NaiveBayers   0.972250  0.709268     0.989351   \n",
       "0  0.968051  0.952213  SupportVectorMachine   0.959939  0.944611     0.979964   \n",
       "0  0.960148  0.940898          DecisionTree   0.951097  0.930915     0.975258   \n",
       "0  0.912141  0.872825      AdaptiveBoosting   0.893151  0.853403     0.944228   \n",
       "0  0.961577  0.942939          RandomForest   0.950655  0.935348     0.975054   \n",
       "0  0.966874  0.950540   K-NearestNeighbours   0.956785  0.944375     0.978313   \n",
       "0  0.969901  0.955160         NeuralNetwork   0.958763  0.951585     0.979206   \n",
       "\n",
       "   Accuract with cv  Deviation(+/-)       time  \n",
       "0          0.965496        0.027315  26.088325  \n",
       "0          0.898476        0.047940   0.261091  \n",
       "0          0.965572        0.028507  26.565346  \n",
       "0          0.955507        0.028288   4.076963  \n",
       "0          0.792513        0.195135  54.658319  \n",
       "0          0.959998        0.031809  54.048197  \n",
       "0          0.964361        0.029316  28.367278  \n",
       "0          0.966883        0.026363  45.740651  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = X[[' n_unique_tokens',' n_non_stop_words',' n_non_stop_unique_tokens',' data_channel_is_tech',' data_channel_is_world',\n",
    "    ' rate_positive_words',' rate_negative_words',' LDA_00',' LDA_02',' LDA_04']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of members in any class cannot be less than n_splits=20.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  0\n",
      "TrueNegative_test  11147\n",
      "FlasePositive_test  0\n",
      "FalseNegative_test  747\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e20384a9a1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_classification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-a5568fa0a522>\u001b[0m in \u001b[0;36mall_classification_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#accuracy_score(y_test,y_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LogisticRegression\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NaiveBayers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SupportVectorMachine\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"DecisionTree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ADABoostClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"knn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NeuralNetwork\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logistic done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayers_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-35e051f6536f>\u001b[0m in \u001b[0;36mlogistic_regression_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_recall_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LogisticRegression'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-98a89c23f46b>\u001b[0m in \u001b[0;36mcalculate_recall_precision\u001b[0;34m(name, label, prediction)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# precision is \"how useful the search results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# recall is \"how complete the results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "b1 = all_classification_model(X5,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuract with cv</th>\n",
       "      <th>Deviation(+/-)</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943921</td>\n",
       "      <td>0.918210</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.932503</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.965050</td>\n",
       "      <td>0.940499</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>10.044387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641248</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>NaiveBayers</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671238</td>\n",
       "      <td>0.180967</td>\n",
       "      <td>0.197804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944930</td>\n",
       "      <td>0.919424</td>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>0.932618</td>\n",
       "      <td>0.906599</td>\n",
       "      <td>0.965260</td>\n",
       "      <td>0.940272</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>38.980184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943165</td>\n",
       "      <td>0.917137</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.905811</td>\n",
       "      <td>0.963035</td>\n",
       "      <td>0.939389</td>\n",
       "      <td>0.030148</td>\n",
       "      <td>2.672789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554986</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>AdaptiveBoosting</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.993729</td>\n",
       "      <td>0.564101</td>\n",
       "      <td>0.279188</td>\n",
       "      <td>35.136884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946191</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.939960</td>\n",
       "      <td>0.902616</td>\n",
       "      <td>0.969354</td>\n",
       "      <td>0.942442</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>27.902768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947116</td>\n",
       "      <td>0.921931</td>\n",
       "      <td>K-NearestNeighbours</td>\n",
       "      <td>0.945038</td>\n",
       "      <td>0.899927</td>\n",
       "      <td>0.972190</td>\n",
       "      <td>0.941432</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>3.574392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948041</td>\n",
       "      <td>0.923572</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.942453</td>\n",
       "      <td>0.905432</td>\n",
       "      <td>0.970656</td>\n",
       "      <td>0.942542</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>37.118976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_score                 Model  Precision    Recall  Specificity  \\\n",
       "0  0.943921  0.918210    LogisticRegression   0.932503  0.904348     0.965050   \n",
       "0  0.641248  0.007905           NaiveBayers   1.000000  0.003968     1.000000   \n",
       "0  0.944930  0.919424  SupportVectorMachine   0.932618  0.906599     0.965260   \n",
       "0  0.943165  0.917137          DecisionTree   0.928749  0.905811     0.963035   \n",
       "0  0.554986  0.037811      AdaptiveBoosting   0.717241  0.019417     0.993729   \n",
       "0  0.946191  0.920910          RandomForest   0.939960  0.902616     0.969354   \n",
       "0  0.947116  0.921931   K-NearestNeighbours   0.945038  0.899927     0.972190   \n",
       "0  0.948041  0.923572         NeuralNetwork   0.942453  0.905432     0.970656   \n",
       "\n",
       "   Accuract with cv  Deviation(+/-)       time  \n",
       "0          0.940499        0.028541  10.044387  \n",
       "0          0.671238        0.180967   0.197804  \n",
       "0          0.940272        0.029099  38.980184  \n",
       "0          0.939389        0.030148   2.672789  \n",
       "0          0.564101        0.279188  35.136884  \n",
       "0          0.942442        0.030374  27.902768  \n",
       "0          0.941432        0.028525   3.574392  \n",
       "0          0.942542        0.027055  37.118976  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [3],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'numpy.ndarray'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-bd09c927cfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    210\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    270\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'numpy.ndarray'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "X7 = pd.concat([X6,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X6.corr()\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)\n",
    "cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "corr.style.background_gradient(cmap, axis=1)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_caption(\"Hover to magify\")\\\n",
    "    .set_precision(2)\\\n",
    "    .set_table_styles(magnify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of members in any class cannot be less than n_splits=20.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  0\n",
      "TrueNegative_test  11147\n",
      "FlasePositive_test  0\n",
      "FalseNegative_test  747\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5effd7d731ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# top 5 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' n_unique_tokens'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' n_non_stop_words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' n_non_stop_unique_tokens'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' data_channel_is_tech'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' data_channel_is_world'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' LDA_00'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' LDA_04'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_classification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-a5568fa0a522>\u001b[0m in \u001b[0;36mall_classification_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#accuracy_score(y_test,y_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LogisticRegression\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NaiveBayers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SupportVectorMachine\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"DecisionTree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ADABoostClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"knn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NeuralNetwork\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logistic done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayers_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-35e051f6536f>\u001b[0m in \u001b[0;36mlogistic_regression_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_recall_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LogisticRegression'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3db032a5e282>\u001b[0m in \u001b[0;36mcalculate_recall_precision\u001b[0;34m(name, label, prediction)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# precision is \"how useful the search results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# recall is \"how complete the results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# top 5 features\n",
    "X6 = X[[' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',' data_channel_is_tech',' data_channel_is_world',' LDA_00',' LDA_04']]\n",
    "b3 = all_classification_model(X6,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       ...,\n",
       "       [4],\n",
       "       [4],\n",
       "       [4]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuract with cv</th>\n",
       "      <th>Deviation(+/-)</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.984596</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>0.980329</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>64.771102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901463</td>\n",
       "      <td>0.837583</td>\n",
       "      <td>NaiveBayers</td>\n",
       "      <td>0.964571</td>\n",
       "      <td>0.740142</td>\n",
       "      <td>0.985789</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.267706</td>\n",
       "      <td>0.719466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991592</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>0.986849</td>\n",
       "      <td>0.993955</td>\n",
       "      <td>0.986054</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>64.853213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962334</td>\n",
       "      <td>0.944209</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.948936</td>\n",
       "      <td>0.939529</td>\n",
       "      <td>0.974042</td>\n",
       "      <td>0.913538</td>\n",
       "      <td>0.293186</td>\n",
       "      <td>10.396585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943081</td>\n",
       "      <td>0.914746</td>\n",
       "      <td>AdaptiveBoosting</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.866619</td>\n",
       "      <td>0.984681</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>117.653989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966538</td>\n",
       "      <td>0.949975</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.964769</td>\n",
       "      <td>0.935628</td>\n",
       "      <td>0.982432</td>\n",
       "      <td>0.934841</td>\n",
       "      <td>0.186817</td>\n",
       "      <td>142.853742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>K-NearestNeighbours</td>\n",
       "      <td>0.965066</td>\n",
       "      <td>0.924686</td>\n",
       "      <td>0.982633</td>\n",
       "      <td>0.957023</td>\n",
       "      <td>0.048928</td>\n",
       "      <td>317.645215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993526</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.993871</td>\n",
       "      <td>0.986565</td>\n",
       "      <td>0.996981</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>52.727281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_score                 Model  Precision    Recall  Specificity  \\\n",
       "0  0.989659  0.984472    LogisticRegression   0.984596  0.984347     0.992311   \n",
       "0  0.901463  0.837583           NaiveBayers   0.964571  0.740142     0.985789   \n",
       "0  0.991592  0.987348  SupportVectorMachine   0.987848  0.986849     0.993955   \n",
       "0  0.962334  0.944209          DecisionTree   0.948936  0.939529     0.974042   \n",
       "0  0.943081  0.914746      AdaptiveBoosting   0.968533  0.866619     0.984681   \n",
       "0  0.966538  0.949975          RandomForest   0.964769  0.935628     0.982432   \n",
       "0  0.962838  0.944444   K-NearestNeighbours   0.965066  0.924686     0.982633   \n",
       "0  0.993526  0.990205         NeuralNetwork   0.993871  0.986565     0.996981   \n",
       "\n",
       "   Accuract with cv  Deviation(+/-)        time  \n",
       "0          0.980329        0.038236   64.771102  \n",
       "0          0.869646        0.267706    0.719466  \n",
       "0          0.986054        0.025660   64.853213  \n",
       "0          0.913538        0.293186   10.396585  \n",
       "0          0.750581        0.281553  117.653989  \n",
       "0          0.934841        0.186817  142.853742  \n",
       "0          0.957023        0.048928  317.645215  \n",
       "0          0.990115        0.024506   52.727281  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering all features\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of members in any class cannot be less than n_splits=20.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rishabhjain/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruePositive_test  0\n",
      "TrueNegative_test  11147\n",
      "FlasePositive_test  0\n",
      "FalseNegative_test  747\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d422beeed229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_classification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-a5568fa0a522>\u001b[0m in \u001b[0;36mall_classification_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#accuracy_score(y_test,y_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LogisticRegression\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NaiveBayers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SupportVectorMachine\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"DecisionTree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ADABoostClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"knn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NeuralNetwork\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logistic done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayers_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-35e051f6536f>\u001b[0m in \u001b[0;36mlogistic_regression_model\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_recall_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LogisticRegression'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-98a89c23f46b>\u001b[0m in \u001b[0;36mcalculate_recall_precision\u001b[0;34m(name, label, prediction)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# precision is \"how useful the search results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# recall is \"how complete the results are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "b7 = all_classification_model(X6,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " GaussianNB(priors=None),\n",
       " SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=101, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=15, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=101,\n",
       "             splitter='best'),\n",
       " AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "           n_estimators=100, random_state=None),\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=30, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=-1,\n",
       "             oob_score=False, random_state=101, verbose=0, warm_start=False),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "            weights='uniform'),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"all_models.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = to_read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X1 = data_standardization(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X2 = minmaxscaling(test_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X2=test_X2.drop([' data_channel_is_entertainment'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X2=test_X2.drop([' data_channel_is_lifestyle'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 7)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "#for i in model:\n",
    "a = pickle_model[0].predict(test_X2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
